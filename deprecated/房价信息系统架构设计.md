# 房价信息系统架构设计

## 系统整体架构说明

房价信息系统采用典型的前后端分离架构，包含**数据采集爬虫**、**后端数据服务**、**MySQL数据库**和**前端Web界面**四大部分。各部分通过HTTP接口协同工作。整体流程如下：

1.  **用户前端交互**：用户在Vue3构建的前端界面上进行城市、区域、房型等筛选操作。前端以HTML/CSS呈现界面并通过JS捕获用户输入。
2.  **请求发送**：前端通过RESTful
    API发送HTTP请求到Python后端服务器（例如：筛选房源列表或获取价格走势数据）。
3.  **后端处理**：后端基于Flask等Python框架接收请求，按照预定义路由调用对应的处理模块（视图函数）。处理过程中，后端与MySQL数据库交互，执行查询或写入操作（如根据请求的城市/区域筛选房源数据）。
4.  **结果返回**：视图函数在完成业务逻辑后将结果数据封装为JSON响应，Flask返回HTTP响应给前端。
5.  **前端呈现**：前端接收响应数据后，使用Vue的数据绑定机制更新界面，包括刷新房源列表或更新价格走势图。图表通过引入ECharts库实现数据可视化呈现。

上述架构确保了爬虫采集层、后端服务层、数据库存储层和前端展示层的解耦，各组件各司其职。为了提升性能和可用性，可选用缓存、异步队列等技术，但在本地笔记本部署环境下无需复杂组件。

**技术栈**：后端采用Python 3和Flask框架开发REST
API；前端使用Vue3框架构建单页应用，结合ECharts图表库用于价格走势可视化展示。数据存储使用MySQL关系数据库。如下表所示是主要技术选型：

- 后端：Python 3，Flask（或FastAPI）框架
- 前端：Vue.js
  3，HTML5，CSS3，（可选Element-Plus组件库增强UI），ECharts图表库
- 数据库：MySQL 5+
- 爬虫：Python爬虫脚本（Requests/BeautifulSoup或Scrapy等）

这一技术架构在前后端分离的Web系统中非常常见。它利用前端的交互优势和后端的数据处理能力，实现良好的用户体验和可维护性。

## 数据库设计

数据采用MySQL关系数据库存储，设计**城市/区域字典表**、**房源信息表**和**成交记录表**三个主要实体，满足系统查询和分析需求：

- **城市表（City）**：存储支持查询的城市列表。字段示例：`city_id`（主键）、`city_name`（城市名称）等。该表与区域表一对多关联。
- **区域表（Region）**：存储各城市下的区域/行政区信息。字段示例：`region_id`（主键）、`region_name`（区域名）、`city_id`（所属城市，外键关联City表）。通过区域表可规范区域名称，并用于统计分区价格。
- **房源信息表（Listing）**：存储爬取的在售房源详细信息。每条记录代表一套房产挂牌信息，包含以下主要字段：
- `listing_id`：主键ID。
- `city_id`：所属城市ID（外键）。
- `region_id`：所属区域ID（外键）。
- `community`：小区或社区名称（如可获取）。
- `house_type`：户型，描述房型结构（如"2室1厅"）。
- `area`：建筑面积（平方米）。
- `floor`：楼层（如具体楼层/总楼层，例"5/20层"）。
- `unit_price`：单价（元/平方米或台币/坪，根据数据来源存储）。
- `total_price`：总价（万元）。
- `build_year`：建筑年份（如数据可得）。
- `source`：来源网站或数据来源标识（便于追踪数据来源）。
- 其他字段：如朝向、装修情况等，可根据实际采集情况扩展。

索引设计：对`city_id`、`region_id`、`house_type`建立索引，以加速按城市/区域/户型的筛选查询；对价格等字段也可建立索引用于排序。房源表通过外键关联城市和区域，实现数据的规范管理。

- **成交记录表（Transaction）**：存储近三年内的历史成交记录和价格数据，用于绘制价格走势。每条记录代表某城市或区域内一套房产的成交信息。主要字段包括：
- `trans_id`：主键ID。
- `city_id`：城市ID（外键）。
- `region_id`：区域ID（外键）。
- `community`：小区名称（若可获取成交对应的小区）。
- `deal_date`：成交日期（精确到年月，格式YYYY-MM-DD或YYYY-MM）。
- `deal_price`：成交总价（万元）。
- `unit_price`：折合单价（元/平方米）。
- `area`：建筑面积（平方米）。
- `house_type`：户型（可选，同样记录户型以供细分分析）。

为方便绘制价格趋势图，系统可在查询时按月份聚合成交记录计算平均单价走势，或者预先按月汇总存储。例如可建立一个**价格历史表**，记录每月每区域的平均单价。简化起见，本设计直接存储原始成交记录，由后端按需聚合计算趋势。

**设计要点**：价格历史数据的管理是核心，为此可以建立专门的价格变动/历史表，以记录每套房源或每区域的价格变化、调整时间等。通过这些历史数据，可以按区域用SQL聚合函数快速计算某区域的均价、最高价、最低价等指标。例如，通过`GROUP BY region_id, month`对成交记录表聚合，就能得到区域层面的月度均价，用于绘制价格走势折线图。

此外，**关系设计**采用**三范式**原则，消除数据冗余：城市和区域作为维度表分离，房源和成交记录通过外键引用，避免字符串重复存储，提高一致性。对于跨表查询（如查询某区域的房源列表及近三年成交均价），可通过JOIN操作或在应用层做关联，实现数据联动。

如果需要扩展，例如记录用户浏览、收藏等，可以增添相应表。但本系统以房价信息为中心，上述表结构已经涵盖主要需求字段。

## 后端模块设计

后端采用Python 3实现，按照职责划分为爬虫采集模块和Web服务API模块两部分。

- **爬虫采集模块**：负责从各数据源网站抓取房价数据，写入MySQL数据库。可以采用独立的Python脚本或Scrapy爬虫项目实现。爬虫程序定期或按需运行，获取最新的房源和成交数据。其主要流程包括：

- **目标网址分析**：选取数据源网站并分析URL规律。例如大陆城市选择链家网(Ke.com)的二手房列表和成交记录页面，台湾选择591房屋交易网或永庆房屋实价登录页面作为数据源。

- **发送请求**：使用`requests`库模拟浏览器请求页面，携带必要的Headers（如User-Agent）以减少被反爬识别。对于动态内容，必要时使用Selenium等浏览器自动化工具获取页面源码。

- **解析数据**：利用BeautifulSoup或XPath解析HTML，提取所需字段。例如，从列表页解析出房源标题、总价、单价、面积、户型、区域等信息，逐条保存。对成交记录页面，则提取历史成交日期和价格等。解析时注意异常处理，如页面结构变化或反爬验证出现。

- **存储入库**：将清洗后的数据通过MySQL驱动或ORM（如SQLAlchemy）写入数据库相应表中。考虑批量插入提高效率，并避免重复数据（可根据房源唯一ID或链接做去重）。\
  爬虫模块可配置为多线程或异步爬取，加快采集速度。例如按城市或按区域并发抓取多页数据。同时实现**日志记录**，监控爬虫运行状态和数据量，以便调试与维护。

- **反爬策略及规避**：爬虫设计需充分考虑各网站的反爬机制。常见措施和应对思路包括：

- **UA池和IP池**：构建多个User-Agent随机轮换，每次请求使用不同浏览器标识；必要时使用代理IP池，避免单IP请求过于频繁被封禁。实际案例表明，像58同城、安居客、房天下等网站有一定反爬，需要这样做。链家近期也增加了反爬检测，需要使用代理IP、分布式爬取才能获取全量数据。

- **请求频率控制**：加入随机延时和限速机制，模拟真人浏览行为，降低触发反爬的可能。例如每抓取一页随机sleep(1-3秒)或检测到验证码时自动暂停。

- **模拟真实交互**：有的网站会通过前端JS渲染数据或检测浏览器行为。例如台湾591房屋网会加密API响应、拆分地址、前端渲染价格等方式防爬，甚至打开开发者工具都会跳转。对此可使用Selenium模拟浏览器，执行页面脚本后再抓取数据。实际有人分享新版591因JS渲染导致无法直接用requests抓取详情，改用Selenium获取，虽然速度变慢。

- **验证码和登录**：若遇到登录验证或验证码拦截，需考虑采用打码平台识别验证码，或提前获取登录Cookies复用等手段。也可尝试调用目标网站的开放API（如有官方数据接口）以合法途径获取数据。

**数据源建议**：大陆一线城市数据可从链家/贝壳找房获取。链家网提供详尽的二手房在售数据，每套房源包含单价、总价、面积、户型、楼层等，并附有小区历史成交信息，可满足需求。其"成交"频道列出该小区近年的成交记录，可用于收集三年内成交价数据。台湾主要城市则可利用内政部**实价登录**公开数据（每笔房地产实际成交记录）或房仲网站的数据。例如591房屋网和永庆房屋等提供区域房价和成交行情浏览接口。永庆的实价登录查询页面按城市列出所有成交，可分页抓取。要注意台湾数据单位多为"坪"和新台币，需标准化换算为平方米和人民币或在界面上区分显示。

爬虫数据采集可以设计为**定时任务**（如每天凌晨或每周更新），持续补充最新挂牌房源和成交记录，使系统数据保持最新。由于用户部署在本地，数据量较大时可选择只抓取必要范围的数据以控制库容量。例如仅抓取目标城市及主要区域的房源和近3年成交，不必囊括全国所有城市。

- **Web服务API模块**：后端提供RESTful接口供前端调用，实现数据的查询和简易业务逻辑。可使用Flask框架定义各路由，对应功能包括：
- `GET /api/cities`：获取支持的城市列表（及下属区域列表）。后台查询City和Region表，返回城市-区域层级结构，用于前端筛选菜单填充。
- `GET /api/listings`：按条件筛选房源列表。支持查询参数如`city=<城市>&region=<区域>&house_type=<房型>&page=<页码>`等。后端接收参数构造数据库查询，例如通过ORM筛选`city_id`、`region_id`、`house_type`字段并分页（LIMIT/OFFSET）查询。返回结果包括房源列表数据和分页信息。
- `GET /api/price_trend`：获取某城市/区域的价格走势数据。可接受参数如`city=<城市>&region=<区域>`，在后台查询近36个月该区域的平均单价走势。例如通过SQL按月份聚合Transaction表计算均价，返回时间序列数据点供前端绘制折线图。也可以查询Transaction表直接返回该区域所有历史成交记录，让前端自行计算/绘图。
- `GET /api/transactions`（可选）：返回某区域近期成交记录列表。包括成交日期、成交总价、单价、面积等，供前端以表格形式展示最近成交案例。
- 其他接口：如房源详细信息`GET /api/listings/<id>`（返回某条房源的完整信息），或统计接口（比如获取全市平均房价、房源总数等概览数据）。根据需求可扩展。

后端模块内部可按照MVC思想组织：模型层定义SQLAlchemy数据模型映射上述表结构；控制器（视图函数）处理请求和业务逻辑；可以封装服务类如`ListingService`、`TrendService`负责组装复杂查询。这样保持代码清晰，可维护。

在数据查询时，可利用缓存策略提升性能。例如针对价格趋势等相对少变的数据，可在首次计算后缓存结果，后续请求直接返回缓存。但由于本系统数据量和并发都不高，暂可不引入缓存优化。

**安全与错误处理**：后端应考虑基本的错误处理和安全。如对API请求参数做校验（防SQL注入等），对于异常情况返回友好的错误消息和适当的HTTP状态码。部署在本地环境，安全风险较低，但依然应遵循良好开发规范。

## 前端模块设计

前端采用Vue3构建单页应用，通过组件化实现各功能模块，并与后端API交互动态展示数据。界面布局和交互围绕以下功能展开：

- **筛选控件**：页面顶部提供城市、区域、房型筛选菜单，允许用户选择感兴趣的城市/区域和房屋类型。城市和区域下拉菜单数据由后端`/api/cities`接口提供，首次加载时获取。用户更改筛选条件时，会触发对应状态更新和API请求。房型筛选可采用下拉多选框或按钮组（例如"一居/二居/三居..."），前端将选定值作为参数请求房源列表接口。

- **房源列表**：主内容区域以列表或卡片形式分页展示房源信息。每条房源项显示主要字段：小区名、户型、面积、总价、单价、楼层等，必要时可加上发布日期或来源等。Vue通过Ajax请求`/api/listings`获取当前筛选条件下的房源数据，并渲染列表。列表支持分页浏览，底部提供分页控件或"加载更多"按钮。当用户切换页码时，发送新的请求获取下一页数据，实现按需加载。为了用户体验，可在列表上方显示当前筛选条件的汇总（例如"北京 -海淀区 - 二居共找到XX套房源"）。点击某条房源，可设计跳转到原始发布页面（通过存储的来源URL）或展示详细信息弹窗。

- **价格走势图表**：页面下方或侧栏展示选中城市/区域的近三年房价走势折线图。前端使用ECharts库绘制图表。加载页面或用户更改城市/区域时，前端调用`/api/price_trend`接口获取对应的数据序列（例如过去36个月的平均单价）。然后将时间作为X轴、价格作为Y轴，在ECharts中绘制折线趋势图。图表支持tooltip显示每月具体均价，提供直观的走势参考。如果需要，也可在图表上标注重大行情节点（如最高点、最低点）。ECharts与Vue良好集成，数据变化后通过刷新option即可更新图表，无需重建组件。

- **近期成交列表**（可选）：为了丰富信息量，前端还可在价格图旁列出该区域最近的成交案例（例如最近几笔成交的房屋信息）。数据来源于`/api/transactions`接口，展示成交日期、房型、面积、成交价等，让用户了解市场活跃度和类似房源成交价。此列表可以使用表格组件实现，分页展示最近三年内的所有记录或按时间筛选。

- **交互体验**：前端采用Vue3的组合式API或选项式API组织代码，组件划分清晰。可以使用Vue
  Router实现多页面导航（例如首页总览、房源列表页等）。UI样式上，可选用Element
  Plus等UI组件库提供美观的下拉框、表格、分页组件，减少基础样式开发时间。所有与后端交互都通过Axios或Fetch
  API实现，统一封装请求模块处理错误和Loading状态。例如请求开始时显示加载动画，完成后关闭，并对错误返回进行提示。

- **响应式设计**：考虑本地使用场景，前端界面做基本的响应式适配，在笔记本电脑浏览器中能够自适应不同窗口大小。布局上可采用基于Flex/Grid的弹性布局。

前端在首次加载时，可调用一次城市/区域接口填充筛选选项。之后用户每次变更筛选或分页，前端路由状态更新并向后端请求新数据，做到**无需刷新整页**即可更新内容，实现单页应用的流畅体验。

此外，可在前端增加一些**数据概览**模块，例如在首页显示各城市平均房价、房源数量等概括信息，供用户选择城市时参考。但这些属于扩展功能，可根据实际数据丰富程度决定。

**示例**：在一个类似系统中，前端数据概览页面支持按名称和年份筛选数据，点击详情还能跳转原始网站查看详情。本系统的前端设计理念与此类似，即通过多种筛选交互和数据可视化，帮助用户方便地浏览和分析房价信息。

## 爬虫设计与数据来源

**目标数据源**：爬虫需面向大陆和台湾的主要房产信息网站：

- 大陆一线城市（北京、上海、广州、深圳等）：推荐使用链家网（贝壳找房）作为数据源。链家提供城市二手房列表页面，以及对应城市下各区域的小区成交记录页面。例如，北京链家二手房列表可以按照区域分页浏览，在页面中抓取"单价/总价/面积/户型/楼层"等字段；同时，北京链家"成交"频道可以查询特定小区或区域的历史成交。链家网站相对数据真实规范，反爬策略也较"温和"。有实践表明链家对爬虫相对友好，只要模拟正常用户行为即可抓取大量数据。当然，随着反爬机制增强，抓取全量数据可能需要更高级策略。

- 台湾主要都市（台北、新北、台中、台南、高雄等）：可利用台湾591房屋交易网和内政部实价登录资料。591网站汇集二手房出租售信息，但反爬严格。相对而言，台湾内政部提供的**不动产实价登录**系统公开了历年房屋成交记录，涵盖地址、楼层、面积、成交价格等，是真实权威的数据源。虽然格式上需要清洗，但非常有价值，尤其用于价格走势分析。另一个折中办法是利用永庆房屋等中介提供的成交查询页面：永庆整理了实价登录数据按行政区展示，分页查询时可以抓取各区近年的成交记录。Medium上有人采用永庆实价登录网页爬取全台房价历史数据。他发现用Requests爬取少量数据尚可，但批量抓取大范围数据时服务器会报错中断，需要切换**Selenium**来模拟浏览器操作，以防止被封锁。

综合考虑，系统爬虫可以针对不同站点分别定制。例如：编写一个爬虫脚本专门抓取链家网指定城市的二手房列表，获取基本房源信息；再编写一个脚本抓取链家上对应城市的成交记录（或直接抓取实价登录数据）。台湾的数据可通过调用官方提供的开放数据接口（若有）或解析永庆/591等网站获取。

**反爬措施规避**：前面概述的反爬策略在具体实现中需重点关注： -
**Headers模拟**：每次请求带上常见浏览器User-Agent、Accept、Referer等头信息，必要时携带Cookie以模拟登录后的访问。可维护一个**UA池**随机选取。 -
**请求调度**：对于分页很多的网站，不要频繁并发请求同一域名。可以在程序中设置**随机延迟**和**失败重试**机制。一旦遇到HTTP
429/430等频率限制响应，及时休眠一段时间再继续。 -
**IP代理**：准备国内代理IP服务，以应对IP封锁。如果发现某站点抓取一段时间后拒绝响应或返回验证码，可切换IP继续。特别是并发抓取多个城市时，代理IP池可以分散各城市的请求来源。 -
**解析校验**：在解析页面时检查是否返回了预期内容。例如许多反爬会返回一个验证码页面或空数据。如检测到页面结构异常（例如BeautifulSoup查找房源列表节点为空），则判定可能被反爬拦截，可记录日志并更换策略。 -
**合法合规**：遵守目标网站的robots协议和服务条款，在抓取频率和数据用途上保持克制。抓取公开网页数据一般问题不大，但仍应避免过于频繁以致影响网站正常服务。

**数据清洗与整合**：爬虫获取的数据需要适当清洗标准化后存库。例如将价格字符串转为数字，面积统一单位为平方米，户型字符串解析出室/厅数等。不同来源字段命名可能不同，需在入库时对应到数据库表的统一字段。例如591的总价可能是"总价(万)"，链家是直接数值，实价登录数据以成交笔为单位，这些都需要转换统一。可以在爬虫模块中加入清洗函数，在写库前处理好异常值和格式。

**触发机制**：在本地部署环境下，爬虫可采取**手动触发**或**定时任务**。例如用户打开系统后，可以在管理界面点击"更新数据"按钮，由后端触发爬虫脚本运行一次（这需要后端开放一个接口来启动爬虫线程）。或者更简单的，提供说明让用户定期手动运行爬虫脚本（如每周运行一次update_data.py）。由于是本地系统，不必实现复杂的调度服务，用户主动运行即可。

## 本地部署说明

**运行环境依赖**：用户需在本地笔记本电脑上准备以下环境：

- **Python 3**：建议Python 3.9及以上版本，确保兼容所用框架。
- **Node.js 16+ 和 npm**：用于运行和构建Vue3前端项目。
- **MySQL 5.7+ 数据库**：安装MySQL社区版，在本地开启服务。
- 可选工具：MySQL可视化客户端（如Navicat、MySQL
  Workbench）方便查看数据；Chrome浏览器用于调试前端。
  
**部署步骤**：

  1. **获取代码**：将前后端及爬虫代码拷贝到本地目录。例如，项目代码可能分为 `backend/`（后端）、`frontend/`（前端）和 `crawler/`（爬虫脚本）三个子目录。进入相应目录准备执行后续部署步骤。

  2. **配置数据库**：启动本地 MySQL 服务器，创建一个新的数据库（例如命名为 `house_price_db`）。新建一个 MySQL 用户并授权给该数据库，或直接使用 root 用户。记录数据库连接信息（主机、端口、用户名、密码、数据库名）。在后端代码的配置文件中设置数据库连接字符串，例如（若使用 Flask + SQLAlchemy）：

  ```text
  SQLALCHEMY_DATABASE_URI = 'mysql+pymysql://username:password@127.0.0.1:3306/house_price_db'
  ```

  确保数据库用户具备创建表的权限。运行提供的数据库初始化脚本（如果有）或首次启动后端时让 ORM 自动创建表结构。

  3. **安装后端依赖**：进入后端项目目录（例如 `backend/`），执行：

  ```bash
  pip install -r requirements.txt
  ```

  该命令会安装项目所需的 Python 依赖库（如 Flask、SQLAlchemy、requests、BeautifulSoup、pymysql 等）。确保网络正常以便安装依赖。

  4. **安装前端依赖**：进入前端项目目录（例如 `frontend/`），执行：

  ```bash
  npm install
  ```

  根据 `package.json` 安装 Vue3 及前端依赖（Vue Router、Axios、ECharts 等）。如无 npm，可先安装 Node.js（包含 npm）。

  5. **配置前端接口地址**：根据后端实际运行地址，设置前端的 API 基址。如果前后端分开运行且端口不同，需要在前端配置文件中修改 API URL，例如在 `frontend/src/config/index.js` 或相关位置设置：

  ```javascript
  axios.defaults.baseURL = 'http://localhost:5000/api';
  ```

  若使用 Vue 开发代理，可在 `vue.config.js` 中设置代理以解决跨域问题。

  6. **运行爬虫数据导入**：首次部署时需获取初始数据。进入 `crawler/` 目录，运行爬虫脚本，例如：

  ```bash
  python fetch_data.py
  ```

  脚本会抓取房源和成交信息并写入数据库。根据数据量该过程可能需要几分钟到更久。观察日志确认数据写入（如房源数量、页数等）。遇到反爬或失败可调整延时、重试或使用代理。

  7. **启动后端服务**：爬虫完成后启动 Flask 后端提供 API 服务。在 `backend/` 目录下可运行：

  ```bash
  flask run --host=0.0.0.0 --port=5000
  ```

  或：

  ```bash
  python app.py
  ```

  确保后端能连接数据库（启动日志会提示连接状态）并侦听端口。默认地址通常为 `http://localhost:5000`。

  8. **启动前端项目**：在 `frontend/` 目录执行开发服务器：

  ```bash
  npm run serve
  ```

  默认会在如 `http://localhost:8080` 启动并打开浏览器（视项目配置而定）。前端将通过先前配置的 `baseURL` 请求后端并展示数据。若需打包部署，可执行：

  ```bash
  npm run build
  ```

  将生成静态文件，之后可由 Flask 或任何静态服务器托管。

  9. **验证功能**：在浏览器中测试应用的各项功能：切换城市/区域筛选是否生效、列表分页是否正常、价格走势图是否显示等。若遇到前后端联调问题（跨域、接口 404、网络错误等），检查浏览器控制台和后端日志并调整配置。确认主要功能正常后即完成部署。

  附：若希望在局域网其他设备访问，将 Flask 绑定到 `0.0.0.0` 并在前端将 `baseURL` 指向机器 IP；同时确保防火墙/端口设置允许访问。

**本地运行维护**：当需要更新数据时，重复执行爬虫脚本即可刷新数据库内容。考虑到数据会随时间增长，建议定期清理过旧的数据（例如只保留近三年的成交记录，不必要的数据可清除，以保持数据库体量适中）。本系统不涉及复杂的分布式部署，仅需保证MySQL服务和后端、前端程序在本机运行即可，无额外的部署开销。

部署完成后，用户可以在本地通过浏览器访问Vue前端界面，享受城市房价信息的检索和可视化分析功能。在笔记本环境中，由于前后端都在本机，响应会很迅速，体验良好。若需在局域网其他设备访问，可将Flask的host改为`0.0.0.0`并确保前端请求指向本机IP。

**依赖环境总结**：Python3 +Flask后端、Vue3前端、MySQL数据库共同构成运行环境。按上述步骤配置后，整个系统即可在本地成功运行，为用户提供大陆一线城市和台湾主要城市的房源价格、历史成交与走势查询分析功能。

通过这个系统，用户可以方便地筛选城市/区域查看房源列表，直观了解近年的价格变化趋势，为购房决策或市场研究提供数据支持。系统架构清晰、部署简单，具有良好的扩展性，后续可以根据需要增加更多城市或功能模块。

**参考文献**:

- 【18】建模先锋. *房价分析（0）反爬虫机制* (CSDN博客, 2023)
- 【23】sczhengyabin. *链家二手房信息、交易记录爬虫* (GitHub, 2022)
- 【32】weixin_62375676. *Python爬虫逆袭：1小时搞定链家全网二手房数据*
  (CSDN博客, 2025)
- 【2】Hung Min. *房屋實價登錄爬蟲* (Medium, 2020)
- 【21】ceshine. *591租房網自動抓取腳本* (GitHub, 2019)
- 【34】赵小尧. *基于爬虫+Flask+Vue3的二手车数据可视化系统* (CSDN博客,
  2024)
- 【35】FineBI知识库. *楼盘数据管理实用法* (2025)
- 【26】赵小尧. *二手车数据可视化系统 -- 功能展示* (CSDN博客, 2024)
- 【39】赵小尧. *二手车数据可视化 -- 系统亮点* (CSDN博客, 2024)
- 【38】华为云实训. *前后端分离图书管理系统* (Gitee, 2022)
- 【28】ProcessOn模板. *典型Web架构图说明* (2022)

------------------------------------------------------------------------