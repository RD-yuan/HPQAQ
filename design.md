房价信息系统架构设计
系统整体架构说明
房价信息系统采用典型的前后端分离架构，包含数据采集爬虫、后端数据服务、MySQL数据库和前端Web界面四大部分。各部分通过HTTP接口协同工作[1]。整体流程如下：
1.用户前端交互：用户在Vue3构建的前端界面上进行城市、区域、房型等筛选操作[2]。前端以HTML/CSS呈现界面并通过JS捕获用户输入。
2.请求发送：前端通过RESTful API发送HTTP请求到Python后端服务器（例如：筛选房源列表或获取价格走势数据）[2]。
3.后端处理：后端基于Flask等Python框架接收请求，按照预定义路由调用对应的处理模块（视图函数）。处理过程中，后端与MySQL数据库交互，执行查询或写入操作[3]（如根据请求的城市/区域筛选房源数据）。
4.结果返回：视图函数在完成业务逻辑后将结果数据封装为JSON响应，Flask返回HTTP响应给前端[4]。
5.前端呈现：前端接收响应数据后，使用Vue的数据绑定机制更新界面，包括刷新房源列表或更新价格走势图。图表通过引入ECharts库实现数据可视化呈现[5][6]。
上述架构确保了爬虫采集层、后端服务层、数据库存储层和前端展示层的解耦，各组件各司其职。为了提升性能和可用性，可选用缓存、异步队列等技术，但在本地笔记本部署环境下无需复杂组件[1]。
技术栈：后端采用Python 3和Flask框架开发REST API；前端使用Vue3框架构建单页应用，结合ECharts图表库用于价格走势可视化展示[5][7]。数据存储使用MySQL关系数据库。如下表所示是主要技术选型：
后端：Python 3，Flask（或FastAPI）框架[7]
前端：Vue.js 3，HTML5，CSS3，（可选Element-Plus组件库增强UI），ECharts图表库[7]
数据库：MySQL 5+
爬虫：Python爬虫脚本（Requests/BeautifulSoup或Scrapy等）
这一技术架构在前后端分离的Web系统中非常常见[1]。它利用前端的交互优势和后端的数据处理能力，实现良好的用户体验和可维护性。
数据库设计
数据采用MySQL关系数据库存储，设计城市/区域字典表、房源信息表和成交记录表三个主要实体，满足系统查询和分析需求：
城市表（City）：存储支持查询的城市列表。字段示例：city_id（主键）、city_name（城市名称）等。该表与区域表一对多关联。
区域表（Region）：存储各城市下的区域/行政区信息。字段示例：region_id（主键）、region_name（区域名）、city_id（所属城市，外键关联City表）。通过区域表可规范区域名称，并用于统计分区价格[8]。
房源信息表（Listing）：存储爬取的在售房源详细信息。每条记录代表一套房产挂牌信息，包含以下主要字段：
listing_id：主键ID。
city_id：所属城市ID（外键）。
region_id：所属区域ID（外键）。
community：小区或社区名称（如可获取）。
house_type：户型，描述房型结构（如“2室1厅”）[9]。
area：建筑面积（平方米）。
floor：楼层（如具体楼层/总楼层，例“5/20层”）。
unit_price：单价（元/平方米或台币/坪，根据数据来源存储）。
total_price：总价（万元）。
build_year：建筑年份（如数据可得）。
source：来源网站或数据来源标识（便于追踪数据来源）。
其他字段：如朝向、装修情况等，可根据实际采集情况扩展。
索引设计：对city_id、region_id、house_type建立索引，以加速按城市/区域/户型的筛选查询；对价格等字段也可建立索引用于排序。房源表通过外键关联城市和区域，实现数据的规范管理。
成交记录表（Transaction）：存储近三年内的历史成交记录和价格数据，用于绘制价格走势。每条记录代表某城市或区域内一套房产的成交信息。主要字段包括：
trans_id：主键ID。
city_id：城市ID（外键）。
region_id：区域ID（外键）。
community：小区名称（若可获取成交对应的小区）。
deal_date：成交日期（精确到年月，格式YYYY-MM-DD或YYYY-MM）。
deal_price：成交总价（万元）。
unit_price：折合单价（元/平方米）。
area：建筑面积（平方米）。
house_type：户型（可选，同样记录户型以供细分分析）。
为方便绘制价格趋势图，系统可在查询时按月份聚合成交记录计算平均单价走势，或者预先按月汇总存储。例如可建立一个价格历史表，记录每月每区域的平均单价[10]。简化起见，本设计直接存储原始成交记录，由后端按需聚合计算趋势。
设计要点：价格历史数据的管理是核心，为此可以建立专门的价格变动/历史表，以记录每套房源或每区域的价格变化、调整时间等[10]。通过这些历史数据，可以按区域用SQL聚合函数快速计算某区域的均价、最高价、最低价等指标[10][8]。例如，通过GROUP BY region_id, month对成交记录表聚合，就能得到区域层面的月度均价，用于绘制价格走势折线图。
此外，关系设计采用三范式原则，消除数据冗余：城市和区域作为维度表分离，房源和成交记录通过外键引用，避免字符串重复存储，提高一致性[8]。对于跨表查询（如查询某区域的房源列表及近三年成交均价），可通过JOIN操作或在应用层做关联，实现数据联动。
如果需要扩展，例如记录用户浏览、收藏等，可以增添相应表。但本系统以房价信息为中心，上述表结构已经涵盖主要需求字段。
后端模块设计
后端采用Python 3实现，按照职责划分为爬虫采集模块和Web服务API模块两部分。
爬虫采集模块：负责从各数据源网站抓取房价数据，写入MySQL数据库。可以采用独立的Python脚本或Scrapy爬虫项目实现。爬虫程序定期或按需运行，获取最新的房源和成交数据。其主要流程包括：
目标网址分析：选取数据源网站并分析URL规律。例如大陆城市选择链家网 (Ke.com) 的二手房列表和成交记录页面，台湾选择591房屋交易网或永庆房屋实价登录页面作为数据源。
发送请求：使用requests库模拟浏览器请求页面，携带必要的Headers（如User-Agent）以减少被反爬识别[11][12]。对于动态内容，必要时使用Selenium等浏览器自动化工具获取页面源码[13]。
解析数据：利用BeautifulSoup或XPath解析HTML，提取所需字段。例如，从列表页解析出房源标题、总价、单价、面积、户型、区域等信息，逐条保存[14][9]。对成交记录页面，则提取历史成交日期和价格等[15][16]。解析时注意异常处理，如页面结构变化或反爬验证出现[17][18]。
存储入库：将清洗后的数据通过MySQL驱动或ORM（如SQLAlchemy）写入数据库相应表中。考虑批量插入提高效率，并避免重复数据（可根据房源唯一ID或链接做去重）。
爬虫模块可配置为多线程或异步爬取，加快采集速度[19]。例如按城市或按区域并发抓取多页数据。同时实现日志记录，监控爬虫运行状态和数据量，以便调试与维护[19]。
反爬策略及规避：爬虫设计需充分考虑各网站的反爬机制[20]。常见措施和应对思路包括：
UA池和IP池：构建多个User-Agent随机轮换，每次请求使用不同浏览器标识；必要时使用代理IP池，避免单IP请求过于频繁被封禁[21]。实际案例表明，像58同城、安居客、房天下等网站有一定反爬，需要这样做[21]。链家近期也增加了反爬检测，需要使用代理IP、分布式爬取才能获取全量数据[22]。
请求频率控制：加入随机延时和限速机制，模拟真人浏览行为，降低触发反爬的可能[23]。例如每抓取一页随机sleep(1-3秒)或检测到验证码时自动暂停。
模拟真实交互：有的网站会通过前端JS渲染数据或检测浏览器行为。例如台湾591房屋网会加密API响应、拆分地址、前端渲染价格等方式防爬，甚至打开开发者工具都会跳转[24]。对此可使用Selenium模拟浏览器，执行页面脚本后再抓取数据[13]。实际有人分享新版591因JS渲染导致无法直接用requests抓取详情，改用Selenium获取，虽然速度变慢[25]。
验证码和登录：若遇到登录验证或验证码拦截，需考虑采用打码平台识别验证码，或提前获取登录Cookies复用等手段。也可尝试调用目标网站的开放API（如有官方数据接口）以合法途径获取数据。
数据源建议：大陆一线城市数据可从链家/贝壳找房获取[26]。链家网提供详尽的二手房在售数据，每套房源包含单价、总价、面积、户型、楼层等，并附有小区历史成交信息，可满足需求。其“成交”频道列出该小区近年的成交记录，可用于收集三年内成交价数据。台湾主要城市则可利用内政部实价登录公开数据（每笔房地产实际成交记录）或房仲网站的数据。例如591房屋网和永庆房屋等提供区域房价和成交行情浏览接口。永庆的实价登录查询页面按城市列出所有成交，可分页抓取。要注意台湾数据单位多为“坪”和新台币，需标准化换算为平方米和人民币或在界面上区分显示。
爬虫数据采集可以设计为定时任务（如每天凌晨或每周更新），持续补充最新挂牌房源和成交记录，使系统数据保持最新。由于用户部署在本地，数据量较大时可选择只抓取必要范围的数据以控制库容量。例如仅抓取目标城市及主要区域的房源和近3年成交，不必囊括全国所有城市。
Web服务API模块：后端提供RESTful接口供前端调用，实现数据的查询和简易业务逻辑。可使用Flask框架定义各路由，对应功能包括：
GET /api/cities：获取支持的城市列表（及下属区域列表）。后台查询City和Region表，返回城市-区域层级结构，用于前端筛选菜单填充。
GET /api/listings：按条件筛选房源列表。支持查询参数如city=<城市>&region=<区域>&house_type=<房型>&page=<页码>等。后端接收参数构造数据库查询，例如通过ORM筛选city_id、region_id、house_type字段并分页（LIMIT/OFFSET）查询[27]。返回结果包括房源列表数据和分页信息。
GET /api/price_trend：获取某城市/区域的价格走势数据。可接受参数如city=<城市>&region=<区域>，在后台查询近36个月该区域的平均单价走势。例如通过SQL按月份聚合Transaction表计算均价，返回时间序列数据点供前端绘制折线图。也可以查询Transaction表直接返回该区域所有历史成交记录，让前端自行计算/绘图。
GET /api/transactions（可选）：返回某区域近期成交记录列表。包括成交日期、成交总价、单价、面积等，供前端以表格形式展示最近成交案例。
其他接口：如房源详细信息GET /api/listings/<id>（返回某条房源的完整信息），或统计接口（比如获取全市平均房价、房源总数等概览数据）。根据需求可扩展。
后端模块内部可按照MVC思想组织：模型层定义SQLAlchemy数据模型映射上述表结构[28]；控制器（视图函数）处理请求和业务逻辑；可以封装服务类如ListingService、TrendService负责组装复杂查询。这样保持代码清晰，可维护。
在数据查询时，可利用缓存策略提升性能。例如针对价格趋势等相对少变的数据，可在首次计算后缓存结果，后续请求直接返回缓存。但由于本系统数据量和并发都不高，暂可不引入缓存优化。
安全与错误处理：后端应考虑基本的错误处理和安全。如对API请求参数做校验（防SQL注入等），对于异常情况返回友好的错误消息和适当的HTTP状态码。部署在本地环境，安全风险较低，但依然应遵循良好开发规范。
前端模块设计
前端采用Vue3构建单页应用，通过组件化实现各功能模块，并与后端API交互动态展示数据。界面布局和交互围绕以下功能展开：
筛选控件：页面顶部提供城市、区域、房型筛选菜单，允许用户选择感兴趣的城市/区域和房屋类型。城市和区域下拉菜单数据由后端/api/cities接口提供，首次加载时获取。用户更改筛选条件时，会触发对应状态更新和API请求。房型筛选可采用下拉多选框或按钮组（例如“一居/二居/三居…”），前端将选定值作为参数请求房源列表接口。
房源列表：主内容区域以列表或卡片形式分页展示房源信息。每条房源项显示主要字段：小区名、户型、面积、总价、单价、楼层等，必要时可加上发布日期或来源等。Vue通过Ajax请求/api/listings获取当前筛选条件下的房源数据，并渲染列表。列表支持分页浏览，底部提供分页控件或“加载更多”按钮。当用户切换页码时，发送新的请求获取下一页数据，实现按需加载[27]。为了用户体验，可在列表上方显示当前筛选条件的汇总（例如“北京 - 海淀区 - 二居 共找到XX套房源”）。点击某条房源，可设计跳转到原始发布页面（通过存储的来源URL）或展示详细信息弹窗。
价格走势图表：页面下方或侧栏展示选中城市/区域的近三年房价走势折线图。前端使用ECharts库绘制图表[5]。加载页面或用户更改城市/区域时，前端调用/api/price_trend接口获取对应的数据序列（例如过去36个月的平均单价）。然后将时间作为X轴、价格作为Y轴，在ECharts中绘制折线趋势图。图表支持tooltip显示每月具体均价，提供直观的走势参考。如果需要，也可在图表上标注重大行情节点（如最高点、最低点）。ECharts与Vue良好集成，数据变化后通过刷新option即可更新图表，无需重建组件[6]。
近期成交列表（可选）：为了丰富信息量，前端还可在价格图旁列出该区域最近的成交案例（例如最近几笔成交的房屋信息）。数据来源于/api/transactions接口，展示成交日期、房型、面积、成交价等，让用户了解市场活跃度和类似房源成交价。此列表可以使用表格组件实现，分页展示最近三年内的所有记录或按时间筛选。
交互体验：前端采用Vue3的组合式API或选项式API组织代码，组件划分清晰。可以使用Vue Router实现多页面导航（例如首页总览、房源列表页等）。UI样式上，可选用Element Plus等UI组件库提供美观的下拉框、表格、分页组件，减少基础样式开发时间[7]。所有与后端交互都通过Axios或Fetch API实现，统一封装请求模块处理错误和Loading状态[29]。例如请求开始时显示加载动画，完成后关闭，并对错误返回进行提示。
响应式设计：考虑本地使用场景，前端界面做基本的响应式适配，在笔记本电脑浏览器中能够自适应不同窗口大小。布局上可采用基于Flex/Grid的弹性布局。
前端在首次加载时，可调用一次城市/区域接口填充筛选选项。之后用户每次变更筛选或分页，前端路由状态更新并向后端请求新数据，做到无需刷新整页即可更新内容，实现单页应用的流畅体验。
此外，可在前端增加一些数据概览模块，例如在首页显示各城市平均房价、房源数量等概括信息，供用户选择城市时参考。但这些属于扩展功能，可根据实际数据丰富程度决定。
示例：在一个类似系统中，前端数据概览页面支持按名称和年份筛选数据，点击详情还能跳转原始网站查看详情[27]。本系统的前端设计理念与此类似，即通过多种筛选交互和数据可视化，帮助用户方便地浏览和分析房价信息。
爬虫设计与数据来源
目标数据源：爬虫需面向大陆和台湾的主要房产信息网站：
大陆一线城市（北京、上海、广州、深圳等）：推荐使用链家网（贝壳找房）作为数据源。链家提供城市二手房列表页面，以及对应城市下各区域的小区成交记录页面。例如，北京链家二手房列表可以按照区域分页浏览，在页面中抓取“单价/总价/面积/户型/楼层”等字段；同时，北京链家“成交”频道可以查询特定小区或区域的历史成交[30]。链家网站相对数据真实规范，反爬策略也较“温和”。有实践表明链家对爬虫相对友好，只要模拟正常用户行为即可抓取大量数据[31]。当然，随着反爬机制增强，抓取全量数据可能需要更高级策略[22]。
台湾主要都市（台北、新北、台中、台南、高雄等）：可利用台湾591房屋交易网和内政部实价登录资料。591网站汇集二手房出租售信息，但反爬严格[24]。相对而言，台湾内政部提供的不动产实价登录系统公开了历年房屋成交记录，涵盖地址、楼层、面积、成交价格等，是真实权威的数据源。虽然格式上需要清洗，但非常有价值，尤其用于价格走势分析。另一个折中办法是利用永庆房屋等中介提供的成交查询页面：永庆整理了实价登录数据按行政区展示，分页查询时可以抓取各区近年的成交记录[32][33]。Medium上有人采用永庆实价登录网页爬取全台房价历史数据[13]。他发现用Requests爬取少量数据尚可，但批量抓取大范围数据时服务器会报错中断，需要切换Selenium来模拟浏览器操作，以防止被封锁[13][34]。
综合考虑，系统爬虫可以针对不同站点分别定制。例如：编写一个爬虫脚本专门抓取链家网指定城市的二手房列表，获取基本房源信息；再编写一个脚本抓取链家上对应城市的成交记录（或直接抓取实价登录数据）。台湾的数据可通过调用官方提供的开放数据接口（若有）或解析永庆/591等网站获取。
反爬措施规避：前面概述的反爬策略在具体实现中需重点关注： - Headers模拟：每次请求带上常见浏览器User-Agent、Accept、Referer等头信息，必要时携带Cookie以模拟登录后的访问。可维护一个UA池随机选取[11]。 - 请求调度：对于分页很多的网站，不要频繁并发请求同一域名。可以在程序中设置随机延迟[23]和失败重试机制。一旦遇到HTTP 429/430等频率限制响应，及时休眠一段时间再继续。 - IP代理：准备国内代理IP服务，以应对IP封锁。如果发现某站点抓取一段时间后拒绝响应或返回验证码，可切换IP继续[22]。特别是并发抓取多个城市时，代理IP池可以分散各城市的请求来源。 - 解析校验：在解析页面时检查是否返回了预期内容。例如许多反爬会返回一个验证码页面或空数据。如检测到页面结构异常（例如BeautifulSoup查找房源列表节点为空），则判定可能被反爬拦截，可记录日志并更换策略[17][18]。 - 合法合规：遵守目标网站的robots协议和服务条款，在抓取频率和数据用途上保持克制[23]。抓取公开网页数据一般问题不大，但仍应避免过于频繁以致影响网站正常服务。
数据清洗与整合：爬虫获取的数据需要适当清洗标准化后存库。例如将价格字符串转为数字，面积统一单位为平方米，户型字符串解析出室/厅数等。不同来源字段命名可能不同，需在入库时对应到数据库表的统一字段。例如591的总价可能是“总价(万)”，链家是直接数值，实价登录数据以成交笔为单位，这些都需要转换统一。可以在爬虫模块中加入清洗函数，在写库前处理好异常值和格式。
触发机制：在本地部署环境下，爬虫可采取手动触发或定时任务。例如用户打开系统后，可以在管理界面点击“更新数据”按钮，由后端触发爬虫脚本运行一次（这需要后端开放一个接口来启动爬虫线程）。或者更简单的，提供说明让用户定期手动运行爬虫脚本（如每周运行一次update_data.py）。由于是本地系统，不必实现复杂的调度服务，用户主动运行即可。
本地部署说明
运行环境依赖：用户需在本地笔记本电脑上准备以下环境：
Python 3：建议Python 3.9及以上版本，确保兼容所用框架。[28]
Node.js 16+ 和 npm：用于运行和构建Vue3前端项目。[28]
MySQL 5.7+ 数据库：安装MySQL社区版，在本地开启服务。[28]
可选工具：MySQL可视化客户端（如Navicat、MySQL Workbench）方便查看数据；Chrome浏览器用于调试前端。
部署步骤：
1.获取代码：将前后端及爬虫代码拷贝到本地目录。例如，项目代码可能分为/backend（后端）和/frontend（前端）两个子目录，以及/crawler（爬虫脚本）目录。进入相应目录准备执行部署步骤。
2.配置数据库：启动本地MySQL服务器，创建一个新的数据库（例如命名为house_price_db）。新建一个MySQL用户并授权给该数据库，或者直接使用root用户。记录数据库连接信息（主机、端口、用户名、密码、数据库名）。在后端代码的配置文件中设置数据库连接字符串[35]。如果使用Flask+SQLAlchemy，可在配置中设置例如：

 SQLALCHEMY_DATABASE_URI = 'mysql+pymysql://username:password@127.0.0.1:3306/house_price_db'
 确保数据库用户名具备创建表的权限[35]。运行提供的数据库初始化脚本（如果有）或首次启动后端时，让ORM自动创建表结构。
3.安装后端依赖：进入后端项目目录（例如backend/），执行：

 pip install -r requirements.txt
 该命令会安装项目所需的Python依赖库，如Flask、SQLAlchemy、Requests、BeautifulSoup、pymysql驱动等。确保网络正常以安装依赖库。
4.安装前端依赖：进入前端项目目录（例如frontend/），执行：

 npm install
 这将根据package.json安装Vue3及所需的前端依赖（Vue Router、Axios、ECharts等）。如无npm，可先安装Node.js自带的npm工具。
5.配置前端接口地址：根据后端实际运行地址，设置前端的API基址。如果前后端分开运行且端口不同，需要在前端配置文件中修改API URL。如在frontend/src/config/index.js或相关位置，将baseUrl设置为后端服务的地址，例如：

 axios.defaults.baseURL = 'http://localhost:5000/api';
 假设Flask后端运行在本机5000端口[36]。若使用Vue开发代理，可在vue.config.js设置代理后台接口，确保跨域请求顺畅。
6.运行爬虫数据导入：在首次部署时，需先获取初始数据。运行爬虫脚本，例如进入crawler/目录，执行：

 python fetch_data.py
 脚本将按照设计抓取各城市房源和成交信息并写入数据库。视数据量多少，此过程可能持续数分钟到数十分钟不等。请耐心等待，并观察日志输出确认数据成功写入（例如房源数量、页面数的日志）。如果目标网站有防爬限制，可能需要多次尝试或调整脚本参数（可根据日志调整延时或更换IP再运行）。
7.启动后端服务：爬虫完成后，启动Flask后端提供API服务。在backend/目录下执行：

 flask run --host=0.0.0.0 --port=5000
 或使用其它方法（如python app.py）启动Flask应用[37]。确保后端正常连接数据库（启动日志应提示成功连接数据库并侦听端口）。默认监听http://localhost:5000。可以在浏览器打开该地址，若配置了接口文档（如Swagger/Redoc）则会出现接口说明页面[37]。
8.启动前端项目：在frontend/目录执行开发服务器：

 npm run serve
 这将启动本地开发服务器（通常默认端口http://localhost:8080），自动打开浏览器预览应用。如果未自动打开，请手动访问该地址。此时前端会通过先前配置的baseUrl请求后端数据，并展示首页。如果需要正式打包部署，也可以执行npm run build生成静态文件，再由Flask或任意静态服务器提供服务。但开发模式下调试更方便。
9.验证功能：在浏览器中测试应用的各项功能：切换城市/区域筛选是否能加载不同列表，分页是否正常，图表是否显示价格走势。如发现前后端联调问题（比如跨域问题、接口404等），可检查浏览器控制台和后端日志，适当调整配置。确保所有主要功能正常后，即完成部署。
本地运行维护：当需要更新数据时，重复执行爬虫脚本即可刷新数据库内容。考虑到数据会随时间增长，建议定期清理过旧的数据（例如只保留近三年的成交记录，不必要的数据可清除，以保持数据库体量适中）。本系统不涉及复杂的分布式部署，仅需保证MySQL服务和后端、前端程序在本机运行即可，无额外的部署开销。
部署完成后，用户可以在本地通过浏览器访问Vue前端界面，享受城市房价信息的检索和可视化分析功能。在笔记本环境中，由于前后端都在本机，响应会很迅速，体验良好。若需在局域网其他设备访问，可将Flask的host改为0.0.0.0并确保前端请求指向本机IP。
依赖环境总结：Python3 + Flask后端、Vue3前端、MySQL数据库共同构成运行环境[28]。按上述步骤配置后，整个系统即可在本地成功运行，为用户提供大陆一线城市和台湾主要城市的房源价格、历史成交与走势查询分析功能。
通过这个系统，用户可以方便地筛选城市/区域查看房源列表，直观了解近年的价格变化趋势[27]，为购房决策或市场研究提供数据支持。系统架构清晰、部署简单，具有良好的扩展性，后续可以根据需要增加更多城市或功能模块。
参考文献:
【18】建模先锋. 房价分析（0）反爬虫机制[21][17] (CSDN博客, 2023)
【23】sczhengyabin. 链家二手房信息、交易记录爬虫[22] (GitHub, 2022)
【32】weixin_62375676. Python爬虫逆袭：1小时搞定链家全网二手房数据[23] (CSDN博客, 2025)
【2】Hung Min. 房屋實價登錄爬蟲[13] (Medium, 2020)
【21】ceshine. 591租房網自動抓取腳本[25] (GitHub, 2019)
【34】赵小尧. 基于爬虫+Flask+Vue3的二手车数据可视化系统[2][7] (CSDN博客, 2024)
【35】FineBI知识库. 楼盘数据管理实用法[10][8] (2025)
【26】赵小尧. 二手车数据可视化系统 – 功能展示[27] (CSDN博客, 2024)
【39】赵小尧. 二手车数据可视化 – 系统亮点[19] (CSDN博客, 2024)
【38】华为云实训. 前后端分离图书管理系统[28][35] (Gitee, 2022)
【28】ProcessOn模板. 典型Web架构图说明[1] (2022)

[1] web架构图 流程图模板_ProcessOn思维导图、流程图
https://www.processon.com/view/6369ad151e08531a6660e52b
[2] [3] [4] [5] [6] [7] [19] [27] 基于爬虫+flask+vue3的二手车数据可视化系统_flask vue3-CSDN博客
https://blog.csdn.net/zhao_xiaoyao/article/details/140334497
[8] [10] mysql分析有哪些房地产场景？楼盘数据管理实用法 - FineBI数据分析知识库
https://www.finebi.com/blog/article/68fb704828946ecca8d1f9f9
[9] [11] [12] [14] [15] [16] [17] [18] [20] [21] [26] [31] 房价分析（0）反爬虫机制_武汉房价数据应该从哪里爬取-CSDN博客
https://blog.csdn.net/qq_40949048/article/details/129853767
[13] [32] [33] [34] 房屋實價登錄爬蟲. 前一陣子朋友寫了一個永慶房屋實價登錄的爬蟲請我跑，由於有一陣子沒爬蟲了，那就趁著… | by hello this is Hung Min! | Medium
https://b5031631512567.medium.com/%E6%88%BF%E5%B1%8B%E5%AF%A6%E5%83%B9%E7%99%BB%E9%8C%84%E7%88%AC%E8%9F%B2-a2426eea849f
[22] GitHub - sczhengyabin/Lianjia_House_Info: 链家二手房信息、交易记录爬虫，部分数据分析
https://github.com/sczhengyabin/Lianjia_House_Info
[23] Python爬虫逆袭：1小时搞定链家全网二手房数据，新手也能轻松抄作业！_链家爬虫-CSDN博客
https://blog.csdn.net/weixin_62375676/article/details/146815648
[24] 591的話確實聽說檔很兇但因為上面的房源相對比較亂最後才會考慮爬他
https://www.threads.com/@darrell_tw_/post/DMzSck4RcQJ/591%E7%9A%84%E8%A9%B1%E7%A2%BA%E5%AF%A6%E8%81%BD%E8%AA%AA%E6%AA%94%E5%BE%88%E5%85%87%E4%BD%86%E5%9B%A0%E7%82%BA%E4%B8%8A%E9%9D%A2%E7%9A%84%E6%88%BF%E6%BA%90%E7%9B%B8%E5%B0%8D%E6%AF%94%E8%BC%83%E4%BA%82%E6%9C%80%E5%BE%8C%E6%89%8D%E6%9C%83%E8%80%83%E6%85%AE%E7%88%AC%E4%BB%96
[25] ceshine/591scraper: 591租房網自動抓取腳本 - GitHub
https://github.com/ceshine/591scraper
[28] [35] [36] [37] LibraryManagement: 本项目是一个前后端分离的图书管理系统 基于Flask服务的框架 + Vue前端框架
https://gitee.com/Flask-devops/library-management
[29] vue.js使用Fetch API访问RESTful API接口示例 - 小白学苑
http://www.xueai8.com/blog/39
[30] 链家住房-二手房真实成交数据2002-2018年- 经管之家
https://bbs.pinggu.org/thread-10640599-1-1.html